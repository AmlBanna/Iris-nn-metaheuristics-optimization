{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNt7TFlS2e-T",
        "outputId": "fe89440f-6f30-4c44-b479-923db0112a53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x7bd5147fbd00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x7bd507529e10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gen\tnevals\n",
            "0  \t10    \n",
            "1  \t5     \n",
            "2  \t8     \n",
            "3  \t8     \n",
            "4  \t9     \n",
            "5  \t6     \n",
            "Best individual: [-3.0110646961332113, 2.0, 35.397865938826016], Accuracy: 0.9666666388511658\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encode target\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Updated for newer scikit-learn versions\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define Neural Network function\n",
        "def train_and_evaluate(params):\n",
        "    lr, n_hidden, n_neurons = params\n",
        "    lr = 10**lr  # scale learning rate\n",
        "    n_hidden = int(n_hidden)\n",
        "    n_neurons = int(n_neurons)\n",
        "\n",
        "    # Create model\n",
        "    model = keras.Sequential()\n",
        "    model.add(Dense(n_neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for _ in range(n_hidden):\n",
        "        model.add(Dense(n_neurons, activation='relu'))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    # Compile and train\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=10, verbose=0, batch_size=16)\n",
        "\n",
        "    # Evaluate\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return acc\n",
        "\n",
        "# Genetic Algorithm setup\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_lr\", random.uniform, -5, -1)  # log scale for learning rate\n",
        "toolbox.register(\"attr_n_hidden\", random.randint, 1, 3)\n",
        "toolbox.register(\"attr_n_neurons\", random.randint, 5, 50)\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 (toolbox.attr_lr, toolbox.attr_n_hidden, toolbox.attr_n_neurons), n=1)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "def eval_individual(ind):\n",
        "    return train_and_evaluate(ind),\n",
        "\n",
        "toolbox.register(\"evaluate\", eval_individual)\n",
        "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
        "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "# Run Genetic Algorithm\n",
        "population = toolbox.population(n=10)\n",
        "ngen = 5  # Number of generations\n",
        "\n",
        "result, _ = algorithms.eaSimple(population, toolbox, cxpb=0.7, mutpb=0.2, ngen=ngen, verbose=True)\n",
        "\n",
        "# Best solution\n",
        "best_ind = tools.selBest(population, k=1)[0]\n",
        "best_acc = train_and_evaluate(best_ind)\n",
        "print(f\"Best individual: {best_ind}, Accuracy: {best_acc}\") \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9OhTbl-4bjb",
        "outputId": "fc103688-a35b-4ccc-ee02-94f8eef5dbcd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1/5, Best Fitness: 0.9666666388511658\n",
            "Iteration 2/5, Best Fitness: 0.9666666388511658\n",
            "Iteration 3/5, Best Fitness: 1.0\n",
            "Iteration 4/5, Best Fitness: 1.0\n",
            "Iteration 5/5, Best Fitness: 1.0\n",
            "Best parameters: [-3.06950381  1.5586003  39.21930145], Best accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encode target\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Updated for newer scikit-learn versions\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define Neural Network function\n",
        "def train_and_evaluate(params):\n",
        "    lr, n_hidden, n_neurons = params\n",
        "    lr = 10**lr  # Scale learning rate\n",
        "    n_hidden = int(n_hidden)\n",
        "    n_neurons = int(n_neurons)\n",
        "\n",
        "    # Create model\n",
        "    model = keras.Sequential()\n",
        "    model.add(Dense(n_neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for _ in range(n_hidden):\n",
        "        model.add(Dense(n_neurons, activation='relu'))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    # Compile and train\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=10, verbose=0, batch_size=16)\n",
        "\n",
        "    # Evaluate\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return acc\n",
        "\n",
        "# Grey Wolf Optimizer  (GWO)implementation\n",
        "def gwo(fitness_function, dim, bounds, n_agents, n_iter):\n",
        "    # Initialize positions\n",
        "    positions = np.random.uniform(bounds[:, 0], bounds[:, 1], (n_agents, dim))\n",
        "    alpha, beta, delta = np.zeros(dim), np.zeros(dim), np.zeros(dim)\n",
        "    alpha_score, beta_score, delta_score = -np.inf, -np.inf, -np.inf\n",
        "\n",
        "    # Optimization loop\n",
        "    for iter in range(n_iter):\n",
        "        for i in range(n_agents):\n",
        "            fitness = fitness_function(positions[i])\n",
        "            if fitness > alpha_score:\n",
        "                alpha_score, alpha = fitness, positions[i].copy()\n",
        "            elif fitness > beta_score:\n",
        "                beta_score, beta = fitness, positions[i].copy()\n",
        "            elif fitness > delta_score:\n",
        "                delta_score, delta = fitness, positions[i].copy()\n",
        "\n",
        "        # Update positions\n",
        "        a = 2 - iter * (2 / n_iter)  # Linear decrease of exploration\n",
        "        for i in range(n_agents):\n",
        "            for d in range(dim):\n",
        "                r1, r2 = np.random.random(), np.random.random()\n",
        "                A1, C1 = 2 * a * r1 - a, 2 * r2\n",
        "                D_alpha = abs(C1 * alpha[d] - positions[i, d])\n",
        "                X1 = alpha[d] - A1 * D_alpha\n",
        "\n",
        "                r1, r2 = np.random.random(), np.random.random()\n",
        "                A2, C2 = 2 * a * r1 - a, 2 * r2\n",
        "                D_beta = abs(C2 * beta[d] - positions[i, d])\n",
        "                X2 = beta[d] - A2 * D_beta\n",
        "\n",
        "                r1, r2 = np.random.random(), np.random.random()\n",
        "                A3, C3 = 2 * a * r1 - a, 2 * r2\n",
        "                D_delta = abs(C3 * delta[d] - positions[i, d])\n",
        "                X3 = delta[d] - A3 * D_delta\n",
        "\n",
        "                positions[i, d] = (X1 + X2 + X3) / 3\n",
        "\n",
        "            # Ensure within bounds\n",
        "            positions[i, d] = np.clip(positions[i, d], bounds[d, 0], bounds[d, 1])\n",
        "\n",
        "        print(f\"Iteration {iter + 1}/{n_iter}, Best Fitness: {alpha_score}\")\n",
        "\n",
        "    return alpha, alpha_score\n",
        "\n",
        "# Define GWO parameters\n",
        "n_agents = 10\n",
        "n_iter = 5\n",
        "dim = 3  # Number of hyperparameters\n",
        "bounds = np.array([[-5, -1], [1, 3], [5, 50]])  # Bounds for lr, n_hidden, n_neurons\n",
        "\n",
        "# Optimize using GWO\n",
        "def fitness_function(params):\n",
        "    return train_and_evaluate(params)\n",
        "\n",
        "best_params, best_score = gwo(fitness_function, dim, bounds, n_agents, n_iter)\n",
        "print(f\"Best parameters: {best_params}, Best accuracy: {best_score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyxVSTgO6NLa",
        "outputId": "29d1d35b-52ca-4732-c3b9-00149e418a09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyswarm\n",
            "  Downloading pyswarm-0.6.tar.gz (4.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyswarm) (1.26.4)\n",
            "Building wheels for collected packages: pyswarm\n",
            "  Building wheel for pyswarm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyswarm: filename=pyswarm-0.6-py3-none-any.whl size=4464 sha256=e95eee2421fa172cf198902bf26c125856bbc7c56d43c27f35f70551a38f87d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/67/40/62fa158f497f942277cbab8199b05cb61c571ab324e67ad0d6\n",
            "Successfully built pyswarm\n",
            "Installing collected packages: pyswarm\n",
            "Successfully installed pyswarm-0.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stopping search: maximum iterations reached --> 5\n",
            "Best Hyperparameters: Learning Rate (log): -2.4940564725751453, Hidden Layers: 1, Neurons/Layer: 28\n",
            "Best Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyswarm\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from pyswarm import pso  # PSO library\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encode target\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Updated for newer scikit-learn versions\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Neural Network evaluation function for PSO\n",
        "def train_and_evaluate(params):\n",
        "    lr, n_hidden, n_neurons = params\n",
        "    lr = 10**lr  # Convert from log scale\n",
        "    n_hidden = int(n_hidden)\n",
        "    n_neurons = int(n_neurons)\n",
        "\n",
        "    # Create model\n",
        "    model = keras.Sequential()\n",
        "    model.add(Dense(n_neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for _ in range(n_hidden):\n",
        "        model.add(Dense(n_neurons, activation='relu'))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    # Compile and train\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=10, verbose=0, batch_size=16)\n",
        "\n",
        "    # Evaluate\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    # Negative accuracy because PSO minimizes the function\n",
        "    return -acc\n",
        "\n",
        "# PSO parameter bounds\n",
        "lb = [-5, 1, 5]  # Lower bounds: learning rate, number of hidden layers, neurons per layer\n",
        "ub = [-1, 3, 50]  # Upper bounds: learning rate, number of hidden layers, neurons per layer\n",
        "\n",
        "# Run PSO\n",
        "best_params, best_loss = pso(train_and_evaluate, lb, ub, swarmsize=10, maxiter=5)\n",
        "\n",
        "# Output results\n",
        "best_accuracy = -best_loss  # Convert back to positive accuracy\n",
        "print(f\"Best Hyperparameters: Learning Rate (log): {best_params[0]}, \"\n",
        "      f\"Hidden Layers: {int(best_params[1])}, Neurons/Layer: {int(best_params[2])}\")\n",
        "print(f\"Best Accuracy: {best_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kIFK-XO7HQJ",
        "outputId": "e86ec87f-b5c6-4af9-f89d-f561fb887c53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: [-1, 1, 5], Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import random\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encode target\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Updated for newer scikit-learn versions\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define Neural Network function\n",
        "def train_and_evaluate(params):\n",
        "    lr, n_hidden, n_neurons = params\n",
        "    lr = 10 ** float(lr)  # Ensure lr is treated as a float\n",
        "    n_hidden = int(n_hidden)\n",
        "    n_neurons = int(n_neurons)\n",
        "\n",
        "    # Create model\n",
        "    model = keras.Sequential()\n",
        "    model.add(Dense(n_neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for _ in range(n_hidden):\n",
        "        model.add(Dense(n_neurons, activation='relu'))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    # Compile and train\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=10, verbose=0, batch_size=16)\n",
        "\n",
        "    # Evaluate\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return acc\n",
        "\n",
        "\n",
        "\n",
        "# Ant Colony Optimization\n",
        "class ACO:\n",
        "    def __init__(self, num_ants, num_iterations, alpha, beta, evaporation_rate, pheromone_init):\n",
        "        self.num_ants = num_ants\n",
        "        self.num_iterations = num_iterations\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.evaporation_rate = evaporation_rate\n",
        "        self.pheromone = pheromone_init\n",
        "\n",
        "    def optimize(self, bounds):\n",
        "        best_params = None\n",
        "        best_acc = 0\n",
        "\n",
        "        for _ in range(self.num_iterations):\n",
        "            # Generate solutions (ants)\n",
        "            ants = []\n",
        "            for _ in range(self.num_ants):\n",
        "                params = [self.sample(bound, i) for i, bound in enumerate(bounds)]\n",
        "                ants.append(params)\n",
        "\n",
        "            # Evaluate ants\n",
        "            fitness = [train_and_evaluate(ant) for ant in ants]\n",
        "\n",
        "            # Update best solution\n",
        "            for ant, acc in zip(ants, fitness):\n",
        "                if acc > best_acc:\n",
        "                    best_params = ant\n",
        "                    best_acc = acc\n",
        "\n",
        "            # Update pheromones\n",
        "            self.update_pheromones(ants, fitness, bounds)\n",
        "\n",
        "        return best_params, best_acc\n",
        "\n",
        "    def sample(self, bound, index):\n",
        "        lower, upper = bound\n",
        "        pheromone = self.pheromone[index]\n",
        "        probabilities = (pheromone ** self.alpha) * ((1 / np.arange(lower, upper + 1)) ** self.beta)\n",
        "        probabilities /= probabilities.sum()\n",
        "        return np.random.choice(np.arange(lower, upper + 1), p=probabilities)\n",
        "\n",
        "    def update_pheromones(self, ants, fitness, bounds):\n",
        "        for i, bound in enumerate(bounds):\n",
        "            lower, upper = bound\n",
        "            for j in range(lower, upper + 1):\n",
        "                self.pheromone[i][j - lower] *= (1 - self.evaporation_rate)  # Evaporate pheromones\n",
        "                for ant, acc in zip(ants, fitness):\n",
        "                    if ant[i] == j:\n",
        "                        self.pheromone[i][j - lower] += acc  # Add pheromone for good solutions\n",
        "\n",
        "# Hyperparameter bounds\n",
        "bounds = [(-5, -1), (1, 3), (5, 50)]  # [lr (log scale), n_hidden, n_neurons]\n",
        "\n",
        "# Initialize pheromone trails\n",
        "pheromone_init = [np.ones(upper - lower + 1) for lower, upper in bounds]\n",
        "\n",
        "# ACO Parameters\n",
        "aco = ACO(num_ants=10, num_iterations=5, alpha=1, beta=2, evaporation_rate=0.1, pheromone_init=pheromone_init)\n",
        "\n",
        "# Run ACO\n",
        "best_params, best_acc = aco.optimize(bounds)\n",
        "print(f\"Best parameters: {best_params}, Accuracy: {best_acc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akopgnbQ80uI",
        "outputId": "7e3c1960-58ef-4e0e-9582-a84440f0ccd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation 1, Best Fitness: 1.0\n",
            "Generation 2, Best Fitness: 1.0\n",
            "Generation 3, Best Fitness: 1.0\n",
            "Generation 4, Best Fitness: 1.0\n",
            "Generation 5, Best Fitness: 1.0\n",
            "Best hyperparameters: [-1.89481917  1.13856388  8.06386333], Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encode target\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Updated for newer scikit-learn versions\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define Neural Network function\n",
        "def train_and_evaluate(params):\n",
        "    lr, n_hidden, n_neurons = params\n",
        "    lr = 10**lr  # scale learning rate\n",
        "    n_hidden = int(n_hidden)\n",
        "    n_neurons = int(n_neurons)\n",
        "\n",
        "    # Create model\n",
        "    model = keras.Sequential()\n",
        "    model.add(Dense(n_neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for _ in range(n_hidden):\n",
        "        model.add(Dense(n_neurons, activation='relu'))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    # Compile and train\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=10, verbose=0, batch_size=16)\n",
        "\n",
        "    # Evaluate\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return acc\n",
        "\n",
        "# Firefly Algorithm\n",
        "def firefly_algorithm(num_fireflies=10, max_generations=5, alpha=0.2, beta=1, gamma=1):\n",
        "    # Initialize fireflies with random hyperparameters\n",
        "    fireflies = np.array([[np.random.uniform(-5, -1),  # Learning rate (log scale)\n",
        "                           np.random.randint(1, 4),   # Number of hidden layers\n",
        "                           np.random.randint(5, 50)] # Neurons per layer\n",
        "                          for _ in range(num_fireflies)])\n",
        "\n",
        "    fitness = np.array([train_and_evaluate(firefly) for firefly in fireflies])\n",
        "\n",
        "    for gen in range(max_generations):\n",
        "        for i in range(num_fireflies):\n",
        "            for j in range(num_fireflies):\n",
        "                if fitness[j] > fitness[i]:  # Move firefly i toward firefly j\n",
        "                    distance = np.linalg.norm(fireflies[i] - fireflies[j])\n",
        "                    attraction = beta * np.exp(-gamma * distance**2)\n",
        "                    fireflies[i] += attraction * (fireflies[j] - fireflies[i]) + alpha * np.random.uniform(-1, 1, 3)\n",
        "                    fireflies[i][1] = np.clip(fireflies[i][1], 1, 3)  # Clip to valid ranges\n",
        "                    fireflies[i][2] = np.clip(fireflies[i][2], 5, 50)\n",
        "\n",
        "                    # Update fitness\n",
        "                    fitness[i] = train_and_evaluate(fireflies[i])\n",
        "\n",
        "        # Reduce randomness (alpha) over generations\n",
        "        alpha *= 0.9\n",
        "        print(f\"Generation {gen + 1}, Best Fitness: {np.max(fitness)}\")\n",
        "\n",
        "    best_idx = np.argmax(fitness)\n",
        "    return fireflies[best_idx], np.max(fitness)\n",
        "\n",
        "# Run Firefly Algorithm\n",
        "best_params, best_acc = firefly_algorithm()\n",
        "print(f\"Best hyperparameters: {best_params}, Accuracy: {best_acc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyisnxJl-oga",
        "outputId": "4a170b99-80ee-4b20-a9ea-c72022643e63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x7c402dd10dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x7c402db67370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cycle 1, Best Fitness: 1.0\n",
            "Cycle 2, Best Fitness: 1.0\n",
            "Cycle 3, Best Fitness: 1.0\n",
            "Cycle 4, Best Fitness: 1.0\n",
            "Cycle 5, Best Fitness: 1.0\n",
            "Best hyperparameters: [-2.41500388  1.45785269 35.61580025], Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encode target\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Updated for newer scikit-learn versions\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define Neural Network function\n",
        "def train_and_evaluate(params):\n",
        "    lr, n_hidden, n_neurons = params\n",
        "    lr = 10**lr  # scale learning rate\n",
        "    n_hidden = int(n_hidden)\n",
        "    n_neurons = int(n_neurons)\n",
        "\n",
        "    # Create model\n",
        "    model = keras.Sequential()\n",
        "    model.add(Dense(n_neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for _ in range(n_hidden):\n",
        "        model.add(Dense(n_neurons, activation='relu'))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    # Compile and train\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=10, verbose=0, batch_size=16)\n",
        "\n",
        "    # Evaluate\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return acc\n",
        "\n",
        "# ABC Algorithm\n",
        "def abc_algorithm(num_bees=10, max_cycles=5, limit=3):\n",
        "    # Initialize population of food sources\n",
        "    food_sources = np.array([[np.random.uniform(-5, -1),  # Learning rate (log scale)\n",
        "                              np.random.randint(1, 4),    # Number of hidden layers\n",
        "                              np.random.randint(5, 50)]  # Neurons per layer\n",
        "                             for _ in range(num_bees)])\n",
        "\n",
        "    fitness = np.array([train_and_evaluate(food) for food in food_sources])\n",
        "    trial_counter = np.zeros(num_bees)  # Track stagnation of solutions\n",
        "\n",
        "    for cycle in range(max_cycles):\n",
        "        # Employed Bees Phase\n",
        "        for i in range(num_bees):\n",
        "            new_food = food_sources[i] + np.random.uniform(-1, 1, 3)  # Generate new solution\n",
        "            new_food[1] = np.clip(new_food[1], 1, 3)  # Clip to valid range\n",
        "            new_food[2] = np.clip(new_food[2], 5, 50)\n",
        "            new_fitness = train_and_evaluate(new_food)\n",
        "            if new_fitness > fitness[i]:\n",
        "                food_sources[i] = new_food\n",
        "                fitness[i] = new_fitness\n",
        "                trial_counter[i] = 0  # Reset trial counter\n",
        "            else:\n",
        "                trial_counter[i] += 1\n",
        "\n",
        "        # Onlooker Bees Phase\n",
        "        prob = fitness / np.sum(fitness)\n",
        "        for _ in range(num_bees):\n",
        "            selected = np.random.choice(range(num_bees), p=prob)\n",
        "            new_food = food_sources[selected] + np.random.uniform(-1, 1, 3)\n",
        "            new_food[1] = np.clip(new_food[1], 1, 3)\n",
        "            new_food[2] = np.clip(new_food[2], 5, 50)\n",
        "            new_fitness = train_and_evaluate(new_food)\n",
        "            if new_fitness > fitness[selected]:\n",
        "                food_sources[selected] = new_food\n",
        "                fitness[selected] = new_fitness\n",
        "                trial_counter[selected] = 0\n",
        "\n",
        "        # Scout Bees Phase\n",
        "        for i in range(num_bees):\n",
        "            if trial_counter[i] > limit:\n",
        "                food_sources[i] = [np.random.uniform(-5, -1),\n",
        "                                   np.random.randint(1, 4),\n",
        "                                   np.random.randint(5, 50)]\n",
        "                fitness[i] = train_and_evaluate(food_sources[i])\n",
        "                trial_counter[i] = 0\n",
        "\n",
        "        print(f\"Cycle {cycle + 1}, Best Fitness: {np.max(fitness)}\")\n",
        "\n",
        "    best_idx = np.argmax(fitness)\n",
        "    return food_sources[best_idx], np.max(fitness)\n",
        "\n",
        "# Run ABC Algorithm\n",
        "best_params, best_acc = abc_algorithm()\n",
        "print(f\"Best hyperparameters: {best_params}, Accuracy: {best_acc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq_FVeBWAX0R",
        "outputId": "58aac704-3c48-4722-9c73-ecc55807e6d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, Best Fitness: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py:108: RuntimeWarning: overflow encountered in cast\n",
            "  return ops.EagerTensor(value, ctx.device_name, dtype)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 2, Best Fitness: 1.0\n",
            "Iteration 3, Best Fitness: 1.0\n",
            "Iteration 4, Best Fitness: 1.0\n",
            "Iteration 5, Best Fitness: 1.0\n",
            "Best hyperparameters: [-1.          1.         23.67450663], Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encode target\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Updated for newer scikit-learn versions\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define Neural Network function\n",
        "def train_and_evaluate(params):\n",
        "    lr, n_hidden, n_neurons = params\n",
        "    lr = 10**lr  # scale learning rate, converting to a valid float (positive)\n",
        "\n",
        "    # Ensure valid values for number of hidden layers and neurons\n",
        "    n_hidden = int(np.clip(n_hidden, 1, 3))  # Between 1 and 3 hidden layers\n",
        "    n_neurons = int(np.clip(n_neurons, 5, 50))  # Between 5 and 50 neurons per layer\n",
        "\n",
        "    # Create model\n",
        "    model = keras.Sequential()\n",
        "    model.add(Dense(n_neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for _ in range(n_hidden):\n",
        "        model.add(Dense(n_neurons, activation='relu'))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    # Compile and train\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=10, verbose=0, batch_size=16)\n",
        "\n",
        "    # Evaluate\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return acc\n",
        "\n",
        "# Opposition-Based Whale Optimization Algorithm\n",
        "def obc_woa(pop_size=10, max_iter=5):\n",
        "    # Initialize population\n",
        "    population = np.array([[np.random.uniform(-5, -1),  # Learning rate (log scale)\n",
        "                            np.random.randint(1, 4),    # Number of hidden layers\n",
        "                            np.random.randint(5, 50)]  # Neurons per layer\n",
        "                           for _ in range(pop_size)])\n",
        "\n",
        "    # Evaluate fitness\n",
        "    fitness = np.array([train_and_evaluate(ind) for ind in population])\n",
        "    best_idx = np.argmax(fitness)\n",
        "    best_solution = population[best_idx]\n",
        "    best_fitness = fitness[best_idx]\n",
        "\n",
        "    for iteration in range(max_iter):\n",
        "        a = 2 - iteration * (2 / max_iter)  # Decreasing factor\n",
        "        for i in range(len(population)):\n",
        "            r1, r2 = np.random.rand(), np.random.rand()\n",
        "            A = 2 * a * r1 - a\n",
        "            C = 2 * r2\n",
        "            p = np.random.rand()\n",
        "\n",
        "            if p < 0.5:\n",
        "                if abs(A) < 1:\n",
        "                    # Encircle prey\n",
        "                    D = abs(C * best_solution - population[i])\n",
        "                    population[i] = best_solution - A * D\n",
        "                else:\n",
        "                    # Explore\n",
        "                    random_ind = population[np.random.randint(0, len(population))]\n",
        "                    D = abs(C * random_ind - population[i])\n",
        "                    population[i] = random_ind - A * D\n",
        "            else:\n",
        "                # Spiral search\n",
        "                distance_to_best = abs(best_solution - population[i])\n",
        "                b = 1\n",
        "                l = np.random.uniform(-1, 1)\n",
        "                population[i] = (distance_to_best * np.exp(b * l) *\n",
        "                                 np.cos(2 * np.pi * l) + best_solution)\n",
        "\n",
        "            # Clip solutions to valid ranges\n",
        "            population[i][1] = np.clip(population[i][1], 1, 3)  # Number of hidden layers\n",
        "            population[i][2] = np.clip(population[i][2], 5, 50)  # Number of neurons per layer\n",
        "\n",
        "            # Ensure valid range for learning rate\n",
        "            population[i][0] = np.clip(population[i][0], -5, -1)  # Log scale for learning rate\n",
        "\n",
        "            # Ensure all values are positive\n",
        "            population[i] = np.clip(population[i], [-5, 1, 5], [0, 3, 50])\n",
        "\n",
        "        # Evaluate fitness after updating\n",
        "        fitness = np.array([train_and_evaluate(ind) for ind in population])\n",
        "\n",
        "        # Update best solution\n",
        "        new_best_idx = np.argmax(fitness)\n",
        "        if fitness[new_best_idx] > best_fitness:\n",
        "            best_solution = population[new_best_idx]\n",
        "            best_fitness = fitness[new_best_idx]\n",
        "\n",
        "        print(f\"Iteration {iteration + 1}, Best Fitness: {best_fitness}\")\n",
        "\n",
        "        # Opposition-based learning\n",
        "        if iteration % 2 == 0:  # Every alternate iteration\n",
        "            # Create opposite population with the same size as the current population\n",
        "            opposite_population = -population + 2 * np.random.uniform(-5, 50, size=population.shape)\n",
        "            opposite_fitness = np.array([train_and_evaluate(ind) for ind in opposite_population])\n",
        "\n",
        "            # Combine current population and opposite population\n",
        "            combined_population = np.vstack((population, opposite_population))\n",
        "            combined_fitness = np.hstack((fitness, opposite_fitness))\n",
        "\n",
        "            # Select the best solutions\n",
        "            sorted_indices = np.argsort(combined_fitness)[::-1][:pop_size]\n",
        "            population = combined_population[sorted_indices]\n",
        "            fitness = combined_fitness[sorted_indices]\n",
        "\n",
        "    return best_solution, best_fitness\n",
        "\n",
        "# Run OBC-WOA\n",
        "best_params, best_acc = obc_woa()\n",
        "print(f\"Best hyperparameters: {best_params}, Accuracy: {best_acc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iik0cmssHX5J",
        "outputId": "12623011-3eb6-46b8-cd89-697cc645d760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results1 have been saved to optimization_results.docx\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from docx import Document\n",
        "\n",
        "def save_results_to_word(results, file_name=\"optimization_results.docx\"):\n",
        "    # Create a Document object\n",
        "    doc = Document()\n",
        "\n",
        "    # Add Title\n",
        "    doc.add_heading('Optimization Algorithm Comparison', 0)\n",
        "\n",
        "    # Add a summary or introductory paragraph\n",
        "    doc.add_paragraph(\"This document contains the results from various optimization algorithms (Genetic Algorithm, Firefly Algorithm, etc.) \"\n",
        "                      \"used to optimize hyperparameters for training a neural network on the Iris dataset.\")\n",
        "\n",
        "    # Add results for each optimization technique\n",
        "    for method, result in results.items():\n",
        "        doc.add_heading(f'{method} Results', level=1)\n",
        "        doc.add_paragraph(f\"Best Hyperparameters: {result['best_params']}\")\n",
        "        doc.add_paragraph(f\"Best Accuracy: {result['best_acc']}\")\n",
        "\n",
        "    # Save the document\n",
        "    doc.save(file_name)\n",
        "\n",
        "results = {\n",
        "    \"Genetic Algorithm\": {\n",
        "        \"best_params\": [-3.0110646961332113, 2.0, 35.397865938826016],\n",
        "        \"best_acc\": 0.9666666388511658\n",
        "    },\n",
        "    \"Firefly Algorithm\": {\n",
        "        \"best_params\":[-1.89481917 , 1.13856388 , 8.06386333],\n",
        "        \"best_acc\":  1.0\n",
        "    },\n",
        "     \"GWO\": {\n",
        "        \"best_params\":[-3.06950381 , 1.5586003 , 39.21930145],\n",
        "        \"best_acc\": 1.0\n",
        "    },\n",
        "      \"PSO\": {\n",
        "        \"best_params\": [-2.4940564725751453, 1, 28],\n",
        "        \"best_acc\": 1.0\n",
        "    },\n",
        "      \"ACO\": {\n",
        "        \"best_params\": [-1, 1, 5],\n",
        "        \"best_acc\": 1.0\n",
        "    },\n",
        "      \"ABC\": {\n",
        "        \"best_params\": [-2.41500388 , 1.45785269 ,35.61580025],\n",
        "        \"best_acc\": 1.0\n",
        "    },\n",
        "      \"OBC-WOA\": {\n",
        "        \"best_params\": [-1,  1  , 23.67450663],\n",
        "        \"best_acc\": 0.96\n",
        "    }\n",
        "     \n",
        "}\n",
        "\n",
        "# Save results to a Word file\n",
        "save_results_to_word(results)\n",
        "print(\"Results1 have been saved to optimization_results.docx\")\n",
        "8"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "Welcome to Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
